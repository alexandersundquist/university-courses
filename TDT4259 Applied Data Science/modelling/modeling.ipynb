{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries & Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "# Seed for reproducibility\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data & filter relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV file\n",
    "listings = pd.read_csv('data/listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only useful columns (see Lukas' list on GoogleDrive)\n",
    "# plus remove neighbourhood & all things 'review'\n",
    "# also remove 'property type' as mapping this on an ordinal scale is too complex\n",
    "columns_to_keep = [\n",
    "    'price', 'host_since', 'host_response_time', 'host_response_rate',\n",
    "    'host_acceptance_rate', 'host_is_superhost', 'host_listings_count',\n",
    "    'host_total_listings_count', 'host_has_profile_pic',\n",
    "    'host_identity_verified',\n",
    "    'latitude', 'longitude', 'room_type', 'accommodates', \n",
    "    'bathrooms', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights',\n",
    "    'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'availability_30',\n",
    "    'availability_60', 'availability_90', 'availability_365', 'instant_bookable', 'calculated_host_listings_count',\n",
    "    'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms',\n",
    "    'calculated_host_listings_count_shared_rooms'\n",
    "]\n",
    "\n",
    "# Keep only the specified columns\n",
    "listings = listings[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['price', 'host_since', 'host_response_time', 'host_response_rate',\n",
      "       'host_acceptance_rate', 'host_is_superhost', 'host_listings_count',\n",
      "       'host_total_listings_count', 'host_has_profile_pic',\n",
      "       'host_identity_verified', 'latitude', 'longitude', 'room_type',\n",
      "       'accommodates', 'bathrooms', 'bedrooms', 'beds', 'minimum_nights',\n",
      "       'maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm',\n",
      "       'availability_30', 'availability_60', 'availability_90',\n",
      "       'availability_365', 'instant_bookable',\n",
      "       'calculated_host_listings_count',\n",
      "       'calculated_host_listings_count_entire_homes',\n",
      "       'calculated_host_listings_count_private_rooms',\n",
      "       'calculated_host_listings_count_shared_rooms'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# List the columns in the data\n",
    "print(listings.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price                                            object\n",
      "host_since                                       object\n",
      "host_response_time                               object\n",
      "host_response_rate                               object\n",
      "host_acceptance_rate                             object\n",
      "host_is_superhost                                object\n",
      "host_listings_count                               int64\n",
      "host_total_listings_count                         int64\n",
      "host_has_profile_pic                             object\n",
      "host_identity_verified                           object\n",
      "latitude                                        float64\n",
      "longitude                                       float64\n",
      "room_type                                        object\n",
      "accommodates                                      int64\n",
      "bathrooms                                       float64\n",
      "bedrooms                                        float64\n",
      "beds                                            float64\n",
      "minimum_nights                                    int64\n",
      "maximum_nights                                    int64\n",
      "minimum_nights_avg_ntm                          float64\n",
      "maximum_nights_avg_ntm                          float64\n",
      "availability_30                                   int64\n",
      "availability_60                                   int64\n",
      "availability_90                                   int64\n",
      "availability_365                                  int64\n",
      "instant_bookable                                 object\n",
      "calculated_host_listings_count                    int64\n",
      "calculated_host_listings_count_entire_homes       int64\n",
      "calculated_host_listings_count_private_rooms      int64\n",
      "calculated_host_listings_count_shared_rooms       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# List the types of the data\n",
    "print(listings.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>minimum_nights_avg_ntm</th>\n",
       "      <th>maximum_nights_avg_ntm</th>\n",
       "      <th>availability_30</th>\n",
       "      <th>availability_60</th>\n",
       "      <th>availability_90</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>8884.000000</td>\n",
       "      <td>9926.000000</td>\n",
       "      <td>8889.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "      <td>10099.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.864046</td>\n",
       "      <td>3.471532</td>\n",
       "      <td>59.921761</td>\n",
       "      <td>10.759973</td>\n",
       "      <td>3.439251</td>\n",
       "      <td>1.144023</td>\n",
       "      <td>1.603768</td>\n",
       "      <td>1.633480</td>\n",
       "      <td>3.973067</td>\n",
       "      <td>314.948411</td>\n",
       "      <td>4.126527</td>\n",
       "      <td>393.328042</td>\n",
       "      <td>13.831072</td>\n",
       "      <td>25.142489</td>\n",
       "      <td>38.363996</td>\n",
       "      <td>134.049609</td>\n",
       "      <td>2.466482</td>\n",
       "      <td>2.093178</td>\n",
       "      <td>0.353401</td>\n",
       "      <td>0.019507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.046270</td>\n",
       "      <td>11.127133</td>\n",
       "      <td>0.020585</td>\n",
       "      <td>0.043214</td>\n",
       "      <td>1.810203</td>\n",
       "      <td>0.405963</td>\n",
       "      <td>0.944112</td>\n",
       "      <td>1.410624</td>\n",
       "      <td>12.245705</td>\n",
       "      <td>363.470626</td>\n",
       "      <td>12.988633</td>\n",
       "      <td>416.183568</td>\n",
       "      <td>11.006389</td>\n",
       "      <td>20.821545</td>\n",
       "      <td>31.670901</td>\n",
       "      <td>122.260856</td>\n",
       "      <td>9.174954</td>\n",
       "      <td>9.098139</td>\n",
       "      <td>1.397438</td>\n",
       "      <td>0.266123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.817260</td>\n",
       "      <td>10.591050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.913290</td>\n",
       "      <td>10.736792</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.922820</td>\n",
       "      <td>10.762670</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>59.931701</td>\n",
       "      <td>10.779821</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>131.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>60.041562</td>\n",
       "      <td>10.942936</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       host_listings_count  host_total_listings_count      latitude  \\\n",
       "count         10099.000000               10099.000000  10099.000000   \n",
       "mean              2.864046                   3.471532     59.921761   \n",
       "std              10.046270                  11.127133      0.020585   \n",
       "min               1.000000                   1.000000     59.817260   \n",
       "25%               1.000000                   1.000000     59.913290   \n",
       "50%               1.000000                   1.000000     59.922820   \n",
       "75%               2.000000                   2.000000     59.931701   \n",
       "max             131.000000                 178.000000     60.041562   \n",
       "\n",
       "          longitude  accommodates    bathrooms     bedrooms         beds  \\\n",
       "count  10099.000000  10099.000000  8884.000000  9926.000000  8889.000000   \n",
       "mean      10.759973      3.439251     1.144023     1.603768     1.633480   \n",
       "std        0.043214      1.810203     0.405963     0.944112     1.410624   \n",
       "min       10.591050      1.000000     0.000000     0.000000     0.000000   \n",
       "25%       10.736792      2.000000     1.000000     1.000000     1.000000   \n",
       "50%       10.762670      3.000000     1.000000     1.000000     1.000000   \n",
       "75%       10.779821      4.000000     1.000000     2.000000     2.000000   \n",
       "max       10.942936     16.000000     5.000000    10.000000    16.000000   \n",
       "\n",
       "       minimum_nights  maximum_nights  minimum_nights_avg_ntm  \\\n",
       "count    10099.000000    10099.000000            10099.000000   \n",
       "mean         3.973067      314.948411                4.126527   \n",
       "std         12.245705      363.470626               12.988633   \n",
       "min          1.000000        1.000000                1.000000   \n",
       "25%          2.000000       30.000000                2.000000   \n",
       "50%          2.000000      365.000000                2.000000   \n",
       "75%          3.000000      365.000000                3.900000   \n",
       "max        500.000000     1500.000000              500.000000   \n",
       "\n",
       "       maximum_nights_avg_ntm  availability_30  availability_60  \\\n",
       "count            10099.000000     10099.000000     10099.000000   \n",
       "mean               393.328042        13.831072        25.142489   \n",
       "std                416.183568        11.006389        20.821545   \n",
       "min                  1.000000         0.000000         0.000000   \n",
       "25%                 30.000000         2.000000         6.000000   \n",
       "50%                365.000000        14.000000        21.000000   \n",
       "75%                365.000000        25.000000        44.000000   \n",
       "max               1500.000000        30.000000        60.000000   \n",
       "\n",
       "       availability_90  availability_365  calculated_host_listings_count  \\\n",
       "count     10099.000000      10099.000000                    10099.000000   \n",
       "mean         38.363996        134.049609                        2.466482   \n",
       "std          31.670901        122.260856                        9.174954   \n",
       "min           0.000000          0.000000                        1.000000   \n",
       "25%          10.000000         22.000000                        1.000000   \n",
       "50%          30.000000         90.000000                        1.000000   \n",
       "75%          69.000000        241.000000                        1.000000   \n",
       "max          90.000000        365.000000                       94.000000   \n",
       "\n",
       "       calculated_host_listings_count_entire_homes  \\\n",
       "count                                 10099.000000   \n",
       "mean                                      2.093178   \n",
       "std                                       9.098139   \n",
       "min                                       0.000000   \n",
       "25%                                       1.000000   \n",
       "50%                                       1.000000   \n",
       "75%                                       1.000000   \n",
       "max                                      94.000000   \n",
       "\n",
       "       calculated_host_listings_count_private_rooms  \\\n",
       "count                                  10099.000000   \n",
       "mean                                       0.353401   \n",
       "std                                        1.397438   \n",
       "min                                        0.000000   \n",
       "25%                                        0.000000   \n",
       "50%                                        0.000000   \n",
       "75%                                        0.000000   \n",
       "max                                       21.000000   \n",
       "\n",
       "       calculated_host_listings_count_shared_rooms  \n",
       "count                                 10099.000000  \n",
       "mean                                      0.019507  \n",
       "std                                       0.266123  \n",
       "min                                       0.000000  \n",
       "25%                                       0.000000  \n",
       "50%                                       0.000000  \n",
       "75%                                       0.000000  \n",
       "max                                       6.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of missing values for all the columns with missing values:\n",
      "price                   1249\n",
      "host_response_time      2117\n",
      "host_response_rate      2117\n",
      "host_acceptance_rate    1309\n",
      "host_is_superhost        104\n",
      "bathrooms               1215\n",
      "bedrooms                 173\n",
      "beds                    1210\n",
      "dtype: int64\n",
      "\n",
      "Amount of columns with missing values:\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Identify missing values in the listings DataFrame\n",
    "missing_values = listings.isnull().sum()\n",
    "\n",
    "#Print the count of missing values for all the columns with missing values\n",
    "print(\"Count of missing values for all the columns with missing values:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Amount of columns with missing values\n",
    "print(\"\\nAmount of columns with missing values:\")\n",
    "print(len(missing_values[missing_values > 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlier counts using Z-score:\n",
      "                                          Column  Outlier Count\n",
      "0                            host_listings_count            111\n",
      "1                      host_total_listings_count            114\n",
      "2                                       latitude            208\n",
      "3                                      longitude            121\n",
      "4                                   accommodates            152\n",
      "5                                      bathrooms            226\n",
      "6                                       bedrooms             95\n",
      "7                                           beds            157\n",
      "8                                 minimum_nights             55\n",
      "9                                 maximum_nights              1\n",
      "10                        minimum_nights_avg_ntm             60\n",
      "11                        maximum_nights_avg_ntm              0\n",
      "12                               availability_30              0\n",
      "13                               availability_60              0\n",
      "14                               availability_90              0\n",
      "15                              availability_365              0\n",
      "16                calculated_host_listings_count             94\n",
      "17   calculated_host_listings_count_entire_homes             94\n",
      "18  calculated_host_listings_count_private_rooms            140\n",
      "19   calculated_host_listings_count_shared_rooms             80\n"
     ]
    }
   ],
   "source": [
    "# Identify outliers\n",
    "def count_outliers_z_score(df):\n",
    "    outlier_counts = {}\n",
    "    for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        mean = df[column].mean()\n",
    "        std_dev = df[column].std()\n",
    "        \n",
    "        # Calculate Z-scores\n",
    "        z_scores = (df[column] - mean) / std_dev\n",
    "        \n",
    "        # Count outliers\n",
    "        outliers = df[(z_scores < -3) | (z_scores > 3)]\n",
    "        outlier_counts[column] = len(outliers)\n",
    "    \n",
    "    # Converts to DF for pretty printing\n",
    "    outlier_counts_df = pd.DataFrame(list(outlier_counts.items()), columns=['Column', 'Outlier Count'])\n",
    "    return outlier_counts_df\n",
    "\n",
    "# Get the number of outliers in each column using Z-score\n",
    "outlier_counts_listings = count_outliers_z_score(listings)\n",
    "\n",
    "# Display the outlier counts as a table\n",
    "print(\"\\nOutlier counts using Z-score:\")\n",
    "print(outlier_counts_listings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" plt.figure(figsize=(12, 8))\\nsns.heatmap(numeric_listings.corr(), annot=False, cmap='coolwarm', linewidths=0.5)\\nplt.show() \""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the columns with numeric data\n",
    "numeric_listings = listings.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Visualize correlations between features for float values\n",
    "\"\"\" plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(numeric_listings.corr(), annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(df):\n",
    "    df_copy = df.copy()\n",
    "    # Remove the commas and dollar signs from the price column\n",
    "    df_copy['price'] = df_copy['price'].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "    return df_copy\n",
    "\n",
    "def clean_host_since(df):\n",
    "    df_copy = df.copy()\n",
    "    # convert to datetime column\n",
    "    df_copy['host_since'] = pd.to_datetime(df_copy['host_since'], format='%Y-%m-%d')\n",
    "    # Get today's date\n",
    "    today = pd.to_datetime(datetime.now().date())\n",
    "    # Calculate the difference in days between 'host_since' and today\n",
    "    df_copy['host_since'] = (today - df_copy['host_since']).dt.days.astype('float64')\n",
    "    return df_copy\n",
    "\n",
    "def clean_host_response_time(df):\n",
    "    df_copy = df.copy()\n",
    "    # Define the mapping from response times to ordinal values\n",
    "    response_time_map = {\n",
    "        'within an hour': 1,\n",
    "        'within a few hours': 2,\n",
    "        'within a day': 3,\n",
    "        'a few days or more': 4\n",
    "    }    \n",
    "    # Apply the mapping to the 'host_response_time' column, replacing values with the ordinal ones\n",
    "    df_copy['host_response_time'] = df_copy['host_response_time'].map(response_time_map)\n",
    "    return df_copy\n",
    "\n",
    "def clean_room_type(df):\n",
    "    df_copy = df.copy()\n",
    "    # Define the mapping from room type to ordinal values\n",
    "    room_type_map = {\n",
    "        'Shared room': 1,\n",
    "        'Hotel room': 2,\n",
    "        'Private room': 2,\n",
    "        'Entire home/apt': 3\n",
    "    }    \n",
    "    # Apply the mapping to the 'room_type' column, replacing values with the ordinal ones\n",
    "    df_copy['room_type'] = df_copy['room_type'].map(room_type_map)\n",
    "    return df_copy\n",
    "\n",
    "def clean_host_response_rate(df):\n",
    "    df_copy = df.copy()\n",
    "    # Remove the percent sign from the column\n",
    "    df_copy['host_response_rate'] = df_copy['host_response_rate'].str.replace(\"%\", \"\").astype(float)\n",
    "    return df_copy\n",
    "\n",
    "def clean_host_acceptance_rate(df):\n",
    "    df_copy = df.copy()\n",
    "    # Remove the percent sign from the column\n",
    "    df_copy['host_acceptance_rate'] = df_copy['host_acceptance_rate'].str.replace(\"%\", \"\").astype(float)\n",
    "    return df_copy\n",
    "\n",
    "def clean_host_is_superhost(df):\n",
    "    df_copy = df.copy()\n",
    "    # Define the mapping to boolean values\n",
    "    boolean_map = {\n",
    "        't': True,\n",
    "        'f': False\n",
    "    }    \n",
    "    # Apply the mapping to the 'host_is_superhost' column, replacing values with the boolean ones\n",
    "    df_copy['host_is_superhost'] = df_copy['host_is_superhost'].map(boolean_map).astype(bool)\n",
    "    return df_copy\n",
    "\n",
    "def clean_host_has_profile_pic(df):\n",
    "    df_copy = df.copy()\n",
    "    # Define the mapping to boolean values\n",
    "    boolean_map = {\n",
    "        't': True,\n",
    "        'f': False\n",
    "    }    \n",
    "    # Apply the mapping to the 'host_has_profile_pic' column, replacing values with the boolean ones\n",
    "    df_copy['host_has_profile_pic'] = df_copy['host_has_profile_pic'].map(boolean_map).astype(bool)\n",
    "    return df_copy\n",
    "\n",
    "def clean_host_identity_verified(df):\n",
    "    df_copy = df.copy()\n",
    "    # Define the mapping to boolean values\n",
    "    boolean_map = {\n",
    "        't': True,\n",
    "        'f': False\n",
    "    }    \n",
    "    # Apply the mapping to the 'host_identity_verified' column, replacing values with the boolean ones\n",
    "    df_copy['host_identity_verified'] = df_copy['host_identity_verified'].map(boolean_map).astype(bool)\n",
    "    return df_copy\n",
    "\n",
    "def clean_instant_bookable(df):\n",
    "    df_copy = df.copy()\n",
    "    # Define the mapping to boolean values\n",
    "    boolean_map = {\n",
    "        't': True,\n",
    "        'f': False\n",
    "    }    \n",
    "    # Apply the mapping to the 'instant_bookable' column, replacing values with the boolean ones\n",
    "    df_copy['instant_bookable'] = df_copy['instant_bookable'].map(boolean_map).astype(bool)\n",
    "    return df_copy\n",
    "\n",
    "def drop_string_columns(df):\n",
    "    #Drop all non-numeric columns\n",
    "    df_copy = df.select_dtypes(include=['float64', 'int64'])\n",
    "    return df_copy\n",
    "\n",
    "def drop_empty_columns(df):\n",
    "    # Drop columns with no values at all\n",
    "    df_copy = df.dropna(axis=1, how='all')\n",
    "    return df_copy\n",
    "\n",
    "def fill_missing_values_mean(df):\n",
    "    # Fill missing values with the mean of the column\n",
    "    df_copy = df.fillna(df.mean())\n",
    "    return df_copy\n",
    "\n",
    "def fill_missing_values_mice(df):\n",
    "    # Initialize the IterativeImputer (MICE)\n",
    "    imputer = IterativeImputer()\n",
    "    # Fit and transform the data\n",
    "    df_copy = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/103494dx1c5gpkpbrpkwnk180000gn/T/ipykernel_89333/750643824.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_copy['price'] = df_copy['price'].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n"
     ]
    }
   ],
   "source": [
    "# Clean columns in the listings data\n",
    "\n",
    "\n",
    "cleaned_listings = clean_price(listings)\n",
    "cleaned_listings = clean_host_since(cleaned_listings)\n",
    "cleaned_listings = clean_host_response_time(cleaned_listings)\n",
    "cleaned_listings = clean_room_type(cleaned_listings)\n",
    "cleaned_listings = clean_host_response_rate(cleaned_listings)\n",
    "cleaned_listings = clean_host_acceptance_rate(cleaned_listings)\n",
    "cleaned_listings = clean_host_is_superhost(cleaned_listings)\n",
    "cleaned_listings = clean_host_has_profile_pic(cleaned_listings)\n",
    "cleaned_listings = clean_host_identity_verified(cleaned_listings)\n",
    "cleaned_listings = clean_instant_bookable(cleaned_listings)\n",
    "# cleaned_listings = drop_string_columns(cleaned_listings)\n",
    "cleaned_listings = drop_empty_columns(cleaned_listings)\n",
    "# cleaned_listings = fill_missing_values_mean(cleaned_listings)\n",
    "cleaned_listings = fill_missing_values_mice(cleaned_listings)\n",
    "\n",
    "# Assert all values are numeric\n",
    "assert cleaned_listings.dtypes.all() != np.dtype('O'), 'Not all values are numeric'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10099 entries, 0 to 10098\n",
      "Data columns (total 30 columns):\n",
      " #   Column                                        Dtype  \n",
      "---  ------                                        -----  \n",
      " 0   price                                         float64\n",
      " 1   host_since                                    float64\n",
      " 2   host_response_time                            float64\n",
      " 3   host_response_rate                            float64\n",
      " 4   host_acceptance_rate                          float64\n",
      " 5   host_is_superhost                             float64\n",
      " 6   host_listings_count                           float64\n",
      " 7   host_total_listings_count                     float64\n",
      " 8   host_has_profile_pic                          float64\n",
      " 9   host_identity_verified                        float64\n",
      " 10  latitude                                      float64\n",
      " 11  longitude                                     float64\n",
      " 12  room_type                                     float64\n",
      " 13  accommodates                                  float64\n",
      " 14  bathrooms                                     float64\n",
      " 15  bedrooms                                      float64\n",
      " 16  beds                                          float64\n",
      " 17  minimum_nights                                float64\n",
      " 18  maximum_nights                                float64\n",
      " 19  minimum_nights_avg_ntm                        float64\n",
      " 20  maximum_nights_avg_ntm                        float64\n",
      " 21  availability_30                               float64\n",
      " 22  availability_60                               float64\n",
      " 23  availability_90                               float64\n",
      " 24  availability_365                              float64\n",
      " 25  instant_bookable                              float64\n",
      " 26  calculated_host_listings_count                float64\n",
      " 27  calculated_host_listings_count_entire_homes   float64\n",
      " 28  calculated_host_listings_count_private_rooms  float64\n",
      " 29  calculated_host_listings_count_shared_rooms   float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 2.3 MB\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_info_rows', 100)\n",
    "cleaned_listings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets where y is the price and X is the rest of the data\n",
    "y = cleaned_listings['price']\n",
    "X = cleaned_listings.drop('price', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled data back to DataFrame for better readability\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 1.29239693e-02  7.09659602e+01 -4.41660780e+00  5.36404114e+00\n",
      " -1.38714327e+01 -3.01073615e+01  3.10899262e+01  2.92482606e+02\n",
      "  4.90053782e+01 -4.35344310e+03 -2.77028265e+03  4.31582907e+02\n",
      "  1.72692014e+02  6.25188003e+02  2.61894510e+02 -1.89024968e+01\n",
      "  2.70693601e-01  1.55865446e-01  2.08818675e-01 -2.51403946e-02\n",
      " -1.50809625e+01  2.01036421e+01  3.46589851e+00 -1.38457549e-01\n",
      "  2.81343722e+01 -8.46640903e+02  8.44266393e+02  8.02203237e+02\n",
      "  7.59331235e+02]\n",
      "Intercept: 288482.9582557991\n",
      "R^2: 0.27227037345203386\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print the coefficients and intercept\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"R^2:\", model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Linear regression\n",
    "- Surprisingly good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -1.773695927644197\n",
      "[1384.5 1159.5 1262.7 1255.7  769.8]\n",
      "[ 700. 1000. 1200. 1429.  800.]\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(max_depth=15, random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Print the R^2 score\n",
    "print(\"R^2:\", model.score(X_test, y_test))\n",
    "\n",
    "# Print the first 5 predictions rounding to 1 decimal place\n",
    "print(np.round(predictions[:5], 1))\n",
    "\n",
    "# Print the first 5 actual values\n",
    "print(np.round(y_test[:5].values,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Decision Tree\n",
    "- Bad. Forget about it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=25; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=25; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=25; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=25; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25; total time=   1.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=25; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=25; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=25; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=25; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=25; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=25; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=25; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=25; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=25; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=25; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=25; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=25; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=25; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=25; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 10], 'min_samples_leaf': [2, 4],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [25, 50]},\n",
       "             verbose=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50],\n",
    "    'max_depth': [None, 10,],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestRegressor(random_state=SEED)\n",
    "\n",
    "# Initialize the grid search\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best R^2 score:  0.1497939979033689\n",
      "R^2 on test set:  0.2642691511720283\n",
      "[1496.2 1151.3 1172.9 1438.5 1077.6]\n",
      "[ 700. 1000. 1200. 1429.  800.]\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best R^2 score: \", grid_search.best_score_)\n",
    "\n",
    "# Pick the best estimator to make predictions\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "rf_predictions = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Print the R^2 score on the test set\n",
    "print(\"R^2 on test set: \", best_rf_model.score(X_test_scaled, y_test))\n",
    "\n",
    "# Print the first 5 predictions rounding to 1 decimal place\n",
    "print(np.round(rf_predictions[:5], 1))\n",
    "\n",
    "# Print the first 5 actual values\n",
    "print(np.round(y_test[:5].values, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" plt.scatter(rf_predictions, residuals)\\nplt.hlines(0, min(rf_predictions), max(rf_predictions), colors='r', linestyles='dashed')\\nplt.xlabel('Predicted Values')\\nplt.ylabel('Residuals')\\nplt.title('Residual Plot')\\nplt.show() \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "residuals = y_test - rf_predictions\n",
    "\"\"\" plt.scatter(rf_predictions, residuals)\n",
    "plt.hlines(0, min(rf_predictions), max(rf_predictions), colors='r', linestyles='dashed')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Random Forest\n",
    "- Better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.01\n",
      "R^2: 0.22486948965833142\n",
      "First 5 predictions: [1582.  1277.2 1413.4 1413.4 1277.2]\n",
      "First 5 actual values: [ 700. 1000. 1200. 1429.  800.]\n",
      "\n",
      "\n",
      "Learning rate: 0.02\n",
      "R^2: 0.27783933299832464\n",
      "First 5 predictions: [1702.9 1166.9 1332.9 1359.9 1189.4]\n",
      "First 5 actual values: [ 700. 1000. 1200. 1429.  800.]\n",
      "\n",
      "\n",
      "Learning rate: 0.022\n",
      "R^2: 0.2855549910086481\n",
      "First 5 predictions: [1866.4 1145.4 1335.  1353.7 1199.6]\n",
      "First 5 actual values: [ 700. 1000. 1200. 1429.  800.]\n",
      "\n",
      "\n",
      "Learning rate: 0.025\n",
      "R^2: 0.2846546391366154\n",
      "First 5 predictions: [1951.5 1128.8 1349.6 1363.  1203.5]\n",
      "First 5 actual values: [ 700. 1000. 1200. 1429.  800.]\n",
      "\n",
      "\n",
      "Learning rate: 0.05\n",
      "R^2: 0.08986095870945021\n",
      "First 5 predictions: [1874.6 1116.1 1266.9 1311.  1207.7]\n",
      "First 5 actual values: [ 700. 1000. 1200. 1429.  800.]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.01, 0.02, 0.022, 0.025, 0.05]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    gb_model = GradientBoostingRegressor(learning_rate=lr, random_state=SEED)\n",
    "    gb_model.fit(X_train_scaled, y_train)\n",
    "    gb_predictions = gb_model.predict(X_test_scaled)\n",
    "    \n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(\"R^2:\", gb_model.score(X_test_scaled, y_test))\n",
    "    print(\"First 5 predictions:\", np.round(gb_predictions[:5], 1))\n",
    "    print(\"First 5 actual values:\", np.round(y_test[:5].values, 1))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Gradient Boosting\n",
    "- Okayish, best with low learning rate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV] END ....................n_neighbors=10, weights=uniform; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=10, weights=uniform; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=10, weights=distance; total time=   0.8s\n",
      "[CV] END ...................n_neighbors=10, weights=distance; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=11, weights=uniform; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=11, weights=uniform; total time=   0.7s\n",
      "[CV] END ...................n_neighbors=10, weights=distance; total time=   0.9s\n",
      "[CV] END ....................n_neighbors=10, weights=uniform; total time=   1.1s\n",
      "[CV] END ...................n_neighbors=11, weights=distance; total time=   0.8s\n",
      "[CV] END ...................n_neighbors=12, weights=distance; total time=   0.6s\n",
      "[CV] END ...................n_neighbors=11, weights=distance; total time=   0.8s\n",
      "[CV] END ...................n_neighbors=11, weights=distance; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=11, weights=uniform; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=12, weights=uniform; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=12, weights=uniform; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=12, weights=uniform; total time=   1.0s\n",
      "[CV] END ...................n_neighbors=12, weights=distance; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=13, weights=uniform; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=13, weights=uniform; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=13, weights=distance; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=13, weights=uniform; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=12, weights=distance; total time=   1.1s\n",
      "[CV] END ...................n_neighbors=13, weights=distance; total time=   0.8s\n",
      "[CV] END ...................n_neighbors=13, weights=distance; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=14, weights=uniform; total time=   0.7s\n",
      "[CV] END ....................n_neighbors=15, weights=uniform; total time=   0.6s\n",
      "[CV] END ...................n_neighbors=14, weights=distance; total time=   0.7s\n",
      "[CV] END ....................n_neighbors=14, weights=uniform; total time=   0.7s\n",
      "[CV] END ....................n_neighbors=14, weights=uniform; total time=   0.8s\n",
      "[CV] END ...................n_neighbors=14, weights=distance; total time=   0.8s\n",
      "[CV] END ...................n_neighbors=14, weights=distance; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=15, weights=uniform; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=15, weights=uniform; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=15, weights=distance; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=16, weights=distance; total time=   0.6s\n",
      "[CV] END ....................n_neighbors=16, weights=uniform; total time=   0.9s\n",
      "[CV] END ....................n_neighbors=16, weights=uniform; total time=   1.0s\n",
      "[CV] END ...................n_neighbors=15, weights=distance; total time=   1.0s\n",
      "[CV] END ...................n_neighbors=15, weights=distance; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=16, weights=uniform; total time=   0.8s\n",
      "[CV] END ...................n_neighbors=16, weights=distance; total time=   0.6s\n",
      "[CV] END ....................n_neighbors=17, weights=uniform; total time=   0.6s\n",
      "[CV] END ....................n_neighbors=17, weights=uniform; total time=   0.6s\n",
      "[CV] END ...................n_neighbors=17, weights=distance; total time=   0.7s\n",
      "[CV] END ....................n_neighbors=17, weights=uniform; total time=   0.7s\n",
      "[CV] END ...................n_neighbors=17, weights=distance; total time=   0.7s\n",
      "[CV] END ...................n_neighbors=17, weights=distance; total time=   0.8s\n",
      "[CV] END ...................n_neighbors=16, weights=distance; total time=   0.9s\n",
      "[CV] END ....................n_neighbors=18, weights=uniform; total time=   0.6s\n",
      "[CV] END ....................n_neighbors=18, weights=uniform; total time=   0.6s\n",
      "[CV] END ...................n_neighbors=18, weights=distance; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=18, weights=uniform; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=18, weights=distance; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=18, weights=distance; total time=   0.9s\n",
      "[CV] END ....................n_neighbors=19, weights=uniform; total time=   0.9s\n",
      "[CV] END ....................n_neighbors=19, weights=uniform; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=19, weights=uniform; total time=   0.7s\n",
      "[CV] END ...................n_neighbors=19, weights=distance; total time=   0.7s\n",
      "[CV] END ...................n_neighbors=19, weights=distance; total time=   0.7s\n",
      "[CV] END ...................n_neighbors=19, weights=distance; total time=   0.7s\n",
      "[CV] END ....................n_neighbors=20, weights=uniform; total time=   0.7s\n",
      "[CV] END ....................n_neighbors=20, weights=uniform; total time=   0.7s\n",
      "[CV] END ....................n_neighbors=20, weights=uniform; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=20, weights=distance; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=20, weights=distance; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=21, weights=uniform; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=21, weights=uniform; total time=   1.0s\n",
      "[CV] END ...................n_neighbors=20, weights=distance; total time=   1.4s\n",
      "[CV] END ...................n_neighbors=21, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=21, weights=uniform; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=21, weights=distance; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=22, weights=uniform; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=21, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=22, weights=uniform; total time=   0.9s\n",
      "[CV] END ....................n_neighbors=22, weights=uniform; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=23, weights=uniform; total time=   0.7s\n",
      "[CV] END ...................n_neighbors=22, weights=distance; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=22, weights=distance; total time=   1.1s\n",
      "[CV] END ...................n_neighbors=22, weights=distance; total time=   1.1s\n",
      "[CV] END ....................n_neighbors=23, weights=uniform; total time=   1.3s\n",
      "[CV] END ....................n_neighbors=23, weights=uniform; total time=   1.0s\n",
      "[CV] END ...................n_neighbors=23, weights=distance; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=23, weights=distance; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=23, weights=distance; total time=   0.9s\n",
      "[CV] END ....................n_neighbors=24, weights=uniform; total time=   0.9s\n",
      "[CV] END ....................n_neighbors=24, weights=uniform; total time=   1.0s\n",
      "[CV] END ...................n_neighbors=24, weights=distance; total time=   0.9s\n",
      "[CV] END ....................n_neighbors=24, weights=uniform; total time=   1.4s\n",
      "[CV] END ...................n_neighbors=24, weights=distance; total time=   1.0s\n",
      "[CV] END ...................n_neighbors=24, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=25, weights=uniform; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=25, weights=uniform; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=25, weights=uniform; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=25, weights=distance; total time=   1.0s\n",
      "[CV] END ...................n_neighbors=25, weights=distance; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=26, weights=uniform; total time=   0.7s\n",
      "[CV] END ....................n_neighbors=26, weights=uniform; total time=   0.8s\n",
      "[CV] END ...................n_neighbors=25, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=26, weights=uniform; total time=   1.1s\n",
      "[CV] END ...................n_neighbors=26, weights=distance; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=26, weights=distance; total time=   1.0s\n",
      "[CV] END ....................n_neighbors=27, weights=uniform; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=27, weights=uniform; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=26, weights=distance; total time=   1.4s\n",
      "[CV] END ....................n_neighbors=27, weights=uniform; total time=   1.1s\n",
      "[CV] END ...................n_neighbors=27, weights=distance; total time=   1.0s\n",
      "[CV] END ...................n_neighbors=27, weights=distance; total time=   1.1s\n",
      "[CV] END ...................n_neighbors=27, weights=distance; total time=   1.2s\n",
      "[CV] END ....................n_neighbors=28, weights=uniform; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=28, weights=uniform; total time=   0.9s\n",
      "[CV] END ...................n_neighbors=28, weights=distance; total time=   0.7s\n",
      "[CV] END ....................n_neighbors=28, weights=uniform; total time=   1.1s\n",
      "[CV] END ...................n_neighbors=28, weights=distance; total time=   0.8s\n",
      "[CV] END ...................n_neighbors=28, weights=distance; total time=   1.2s\n",
      "[CV] END ...................n_neighbors=29, weights=distance; total time=   0.7s\n",
      "[CV] END ....................n_neighbors=29, weights=uniform; total time=   0.8s\n",
      "[CV] END ....................n_neighbors=29, weights=uniform; total time=   0.9s\n",
      "[CV] END ....................n_neighbors=29, weights=uniform; total time=   0.8s\n",
      "[CV] END ...................n_neighbors=29, weights=distance; total time=   0.4s\n",
      "[CV] END ...................n_neighbors=29, weights=distance; total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=KNeighborsRegressor(), n_jobs=-1,\n",
       "             param_grid={'n_neighbors': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "                                         20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
       "                                         29],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             verbose=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(10, 30)),  \n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# Initialize the grid search\n",
    "grid_search_knn = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_knn.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'n_neighbors': 29, 'weights': 'distance'}\n",
      "Best R^2 score:  0.10717125733733461\n",
      "R^2 on test set:  0.2583721192716234\n",
      "[1391.4  924.  1107.2 1407.8 1027.3]\n",
      "[ 700. 1000. 1200. 1429.  800.]\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", grid_search_knn.best_params_)\n",
    "print(\"Best R^2 score: \", grid_search_knn.best_score_)\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "best_knn_model = grid_search_knn.best_estimator_\n",
    "knn_predictions = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Print the R^2 score on the test set\n",
    "print(\"R^2 on test set: \", best_knn_model.score(X_test_scaled, y_test))\n",
    "\n",
    "# Print the first 5 predictions rounding to 1 decimal place\n",
    "print(np.round(knn_predictions[:5], 1))\n",
    "\n",
    "# Print the first 5 actual values\n",
    "print(np.round(y_test[:5].values, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "- quite okay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, solver=adam; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, solver=adam; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, solver=adam; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, solver=adam; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nf/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=MLPRegressor(max_iter=500, random_state=42),\n",
       "             param_grid={'activation': ['relu', 'tanh'],\n",
       "                         'alpha': [0.0001, 0.001],\n",
       "                         'hidden_layer_sizes': [(50,), (100,)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['adam']},\n",
       "             verbose=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "mlp_model = MLPRegressor(random_state=SEED, max_iter=500)\n",
    "\n",
    "# Initialize the grid search\n",
    "grid_search_mlp = GridSearchCV(estimator=mlp_model, param_grid=param_grid, cv=2, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_mlp.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Best R^2 score:  0.12465880670204954\n",
      "R^2 on test set:  0.2845684004661386\n",
      "[3313.2  905.8  925.9 1449.6  867.1]\n",
      "[ 700. 1000. 1200. 1429.  800.]\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", grid_search_mlp.best_params_)\n",
    "print(\"Best R^2 score: \", grid_search_mlp.best_score_)\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "best_mlp_model = grid_search_mlp.best_estimator_\n",
    "mlp_predictions = best_mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Print the R^2 score on the test set\n",
    "print(\"R^2 on test set: \", best_mlp_model.score(X_test_scaled, y_test))\n",
    "\n",
    "# Print the first 5 predictions rounding to 1 decimal place\n",
    "print(np.round(mlp_predictions[:5], 1))\n",
    "\n",
    "# Print the first 5 actual values\n",
    "print(np.round(y_test[:5].values, 1))\n",
    "\n",
    "\n",
    "# Create a function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "- Needs way more experimenting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
